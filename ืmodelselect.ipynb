{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61658ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. Data Preparation (DE/DA Part)\n",
    "# ==========================================\n",
    "print(\"Step 1: Loading and Splitting Data...\")\n",
    "\n",
    "# โหลดข้อมูล\n",
    "X = new_df.drop(columns=['Churn'])\n",
    "y = new_df['Churn']\n",
    "\n",
    "# --- KEY CONCEPT: Train / Test Split ---\n",
    "# เราแบ่ง Test Set แยกออกมาเลย 20% (Hold-out) เอาไว้สอบ Final\n",
    "# stratify=y คือการบังคับให้สัดส่วน class 0/1 ใน train และ test เท่าๆ กัน (สำคัญมาก!)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}\")\n",
    "print(f\"Test shape:  {X_test.shape}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# ==========================================\n",
    "# 2. Pipeline Construction (DS Part)\n",
    "# ==========================================\n",
    "# อาจารย์จะสร้าง Pipeline กลาง เพื่อกัน Data Leakage\n",
    "# ขั้นตอนคือ: Scale ข้อมูล -> เลือก Feature -> เข้า Model\n",
    "\n",
    "# เราจะทำ Model Selection โดยการเปรียบเทียบ 2 โมเดล: Logistic Regression และ Random Forest\n",
    "\n",
    "pipelines = {\n",
    "    'lr': Pipeline([\n",
    "        ('scaler', StandardScaler()),                # ปรับ Scale (DE/DS)\n",
    "        ('selector', SelectKBest(score_func=f_classif)), # Feature Selection (DS)\n",
    "        ('classifier', LogisticRegression(max_iter=1000)) # Model\n",
    "    ]),\n",
    "    'rf': Pipeline([\n",
    "        ('scaler', StandardScaler()),                # Random Forest ไม่ต้อง Scale ก็ได้แต่ใส่ไว้ไม่เสียหาย\n",
    "        ('selector', SelectKBest(score_func=f_classif)),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 3. Hyperparameter Tuning & Model Selection\n",
    "# ==========================================\n",
    "print(\"Step 2: Training, Tuning & Feature Selection (Cross-Validation)...\")\n",
    "\n",
    "# กำหนด Parameter Grid ที่จะจูน (รวมถึงจำนวน Feature ที่จะเลือกด้วย)\n",
    "param_grids = {\n",
    "    'lr': {\n",
    "        'selector__k': [5, 10, 15, 'all'],           # ลองเลือก feature 5, 10, 15 ตัว หรือทั้งหมด\n",
    "        'classifier__C': [0.1, 1, 10]                # จูนความเข้มข้นของ Regularization\n",
    "    },\n",
    "    'rf': {\n",
    "        'selector__k': [5, 10, 'all'],\n",
    "        'classifier__n_estimators': [50, 100],       # จำนวนต้นไม้\n",
    "        'classifier__max_depth': [None, 10, 20]      # ความลึกของต้นไม้\n",
    "    }\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "results = []\n",
    "\n",
    "# Loop เพื่อแข่งกันระหว่าง Model (Model Selection Logic)\n",
    "for model_name, pipeline in pipelines.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    \n",
    "    # ใช้ GridSearchCV เพื่อทำ Cross-Validation (Validation Set อยู่ในนี้แล้ว)\n",
    "    # cv=5 คือแบ่ง Train data เป็น 5 ส่วน (Train 4, Val 1) วนจนครบ\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grids[model_name],\n",
    "        cv=StratifiedKFold(n_splits=5), # ใช้ Stratified เพื่อความชัวร์เรื่อง Class Imbalance\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1 # ใช้ทุก Core ของ CPU\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Best CV Score': grid_search.best_score_,\n",
    "        'Best Params': grid_search.best_params_\n",
    "    })\n",
    "\n",
    "# ==========================================\n",
    "# 4. Evaluation (Final Exam)\n",
    "# ==========================================\n",
    "print(\"-\" * 30)\n",
    "print(\"Step 3: Final Evaluation on Test Set...\")\n",
    "\n",
    "# เปรียบเทียบผลลัพธ์\n",
    "results_df = pd.DataFrame(results).sort_values(by='Best CV Score', ascending=False)\n",
    "print(\"\\nValidation Results (from Cross-Validation):\")\n",
    "print(results_df)\n",
    "\n",
    "# เลือกผู้ชนะ\n",
    "winner_name = results_df.iloc[0]['Model']\n",
    "winner_model = best_models[winner_name]\n",
    "\n",
    "print(f\"\\n>>> The Winner Model is: {winner_name}\")\n",
    "print(f\">>> Best Parameters: {results_df.iloc[0]['Best Params']}\")\n",
    "\n",
    "# วัดผลกับ Test Set (ที่แอบไว้ตั้งแต่ต้น)\n",
    "y_pred = winner_model.predict(X_test)\n",
    "\n",
    "print(\"\\nFinal Test Set Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ดูว่า Feature ไหนถูกเลือกบ้าง (ถ้าเป็น SelectKBest)\n",
    "mask = winner_model.named_steps['selector'].get_support()\n",
    "selected_features = X.columns[mask]\n",
    "print(f\"Selected Features ({len(selected_features)}): {list(selected_features)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
